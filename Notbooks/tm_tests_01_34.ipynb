{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e5ff48b",
   "metadata": {},
   "source": [
    "# **Text mining: SENTIMENT ANALYSIS**\n",
    "\n",
    "## üéì Master‚Äôs Program in Data Science & Advanced Analytics  \n",
    "**Nova IMS** | June 2025  \n",
    "**Course:** Text Mining\n",
    "\n",
    "## üë• Team **Group 34**  \n",
    "- **[Philippe Dutranoit]** | [20240518]  \n",
    "- **[Diogo Duarte]** | [20240525]  \n",
    "- **[Rui luz]** | [20211628]  \n",
    "- **[Rodrigo Sardinha]** | [20211627]  \n",
    "\n",
    "## üìä Goal of the notebook\n",
    "\n",
    "\n",
    "In this notebook, we assembled baseline pipelines using general‚Äêpurpose classifiers on text data. Although these models aren‚Äôt specifically designed for natural language, they serve as a solid foundation. Moving forward, we can explore more specialized approaches‚Äîsuch as transformer‚Äêbased embeddings, deep learning architectures, or richer feature engineering‚Äîto further enhance performance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f052f0b3",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94787d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch\n",
    "# !pip install tensorflow \n",
    "# !pip install flax  \n",
    "# !pip install nltk\n",
    "# !pip install transformers  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d0d660",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import make_scorer, f1_score , accuracy_score\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71271e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn off tokenizers‚Äô multithreading to avoid fork‚Äêafter‚Äêfork deadlocks\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e7d424eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = pd.read_csv('../Data/X_train.csv')\n",
    "# y_train = pd.read_csv('../Data/y_train.csv')\n",
    "# X_val = pd.read_csv('../Data/X_val.csv')\n",
    "# y_val = pd.read_csv('../Data/y_val.csv')\n",
    "\n",
    "df = pd.read_csv('../Data/train.csv')\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    df['text'], \n",
    "    df['label'], \n",
    "    test_size=0.20,\n",
    "    stratify=df['label'],\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc46e035",
   "metadata": {},
   "source": [
    "# Prepocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7523c099",
   "metadata": {},
   "source": [
    "Here we define our baseline text‚Äêcleaning function, ensuring a consistent starting point across all models.  \n",
    "In later sections, we‚Äôll also integrate pre-trained HuggingFace tokenizers (e.g., BERT, RoBERTa) directly into our pipelines and grid searches, allowing us to compare simple rule‚Äêbased cleaning against state-of-the-art subword tokenization.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0836fd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer() # transform the word to their basic form\n",
    "STOPWORDS = ENGLISH_STOP_WORDS # remove the common words that do not add much meaning\n",
    "\n",
    "def clean_text(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Clean the text by:\n",
    "      1. Lowercasing\n",
    "      2. Stripping URLs\n",
    "      3. Stripping @mentions\n",
    "      4. Stripping # from hashtags\n",
    "      5. Removing non-alphanumeric (keep spaces)\n",
    "      6. Collapsing whitespace\n",
    "      7. Removing stopwords\n",
    "      8. Lemmatizing (if WordNet is available)\n",
    "    \"\"\"\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'http\\S+|www\\.\\S+|https\\S+', '', text)\n",
    "    text = re.sub(r'@\\w+', '', text)\n",
    "    text = re.sub(r'#(\\w+)', r'\\1', text)\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    tokens = text.split()\n",
    "    cleaned = []\n",
    "    for tok in tokens:\n",
    "        if tok not in STOPWORDS:\n",
    "            try:\n",
    "                cleaned.append(lemmatizer.lemmatize(tok))\n",
    "            except:\n",
    "                cleaned.append(tok)\n",
    "    return ' '.join(cleaned)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cb6dde",
   "metadata": {},
   "source": [
    "# Model prep "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a56f552",
   "metadata": {},
   "source": [
    "\n",
    "# %% [markdown]\n",
    "## Section: Model Preparation\n",
    "\n",
    "In this section, we define and tune **four** text‚Äêclassification pipelines:\n",
    "\n",
    "1. **Bag-of-Words + Classifier**  \n",
    "2. **TF-IDF + Classifier**  \n",
    "3. **AutoTokenizer (BERT) ‚Üí BoW & TF-IDF + Classifier**  \n",
    "4. **AutoTokenizer (RoBERTa) ‚Üí BoW & TF-IDF + Classifier**  \n",
    "\n",
    "For each **manual** pipeline (1 & 2), we will:  \n",
    "1. Wrap our shared `clean_text` in a `FunctionTransformer`.  \n",
    "2. Vectorize the cleaned tweets with `CountVectorizer` or `TfidfVectorizer`.  \n",
    "3. Run `GridSearchCV` to find the best hyperparameters.  \n",
    "4. Optimize for **macro F1-score** to treat all classes equally.  \n",
    "\n",
    "For the **AutoTokenizer** workflows (3 & 4), we instead:  \n",
    "1. Load the appropriate HuggingFace `AutoTokenizer` (BERT or RoBERTa).  \n",
    "2. Use its `.tokenize()` method inside `CountVectorizer` and `TfidfVectorizer`.  \n",
    "3. Run `GridSearchCV` and optimize for **macro F1-score** as above.  \n",
    "\n",
    "Finally, we train each model with its selected parameters and compare performance across all four pipelines.  \n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45051af",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40546a9",
   "metadata": {},
   "source": [
    "### Manual cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "839c5c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_xgb_bow_grid(X_train, y_train, cv = 3, n_jobs = -1, verbose = 1):\n",
    "    \"\"\"\n",
    "    Train an XGBoost model using Bag-of-Words features with hyperparameter tuning.\n",
    "    \"\"\"\n",
    "    # cleaning the text data\n",
    "    clean_tf = FunctionTransformer(\n",
    "        func = lambda X: [clean_text(doc) for doc in X],\n",
    "        validate = False\n",
    "    )\n",
    "    \n",
    "    # Build pipeline\n",
    "    pipe = Pipeline([\n",
    "        ('clean', clean_tf),\n",
    "        ('vect',  CountVectorizer()),\n",
    "        ('clf',   XGBClassifier(\n",
    "                      eval_metric='logloss',\n",
    "                      random_state=42\n",
    "                  ))\n",
    "    ])\n",
    "    \n",
    "    param_grid = {\n",
    "    'clf__n_estimators':  [100, 200, 300, 400],\n",
    "    'clf__max_depth':     [3, 6, 9],\n",
    "    'clf__learning_rate': [0.01, 0.05],\n",
    "    'clf__subsample':     [0.8, 1.0]}\n",
    "    \n",
    "    # Use macro-F1 to treat all classes equally\n",
    "    scorer = make_scorer(f1_score, average='macro')\n",
    "    \n",
    "    grid = GridSearchCV(\n",
    "        estimator    = pipe,\n",
    "        param_grid   = param_grid,\n",
    "        scoring      = scorer,\n",
    "        cv           = cv,\n",
    "        n_jobs       = n_jobs,\n",
    "        verbose      = verbose\n",
    "    )\n",
    "    grid.fit(X_train, y_train)\n",
    "    \n",
    "    return grid.best_params_\n",
    "\n",
    "def train_xgb_tfidf_grid(X_train, y_train, cv=3, n_jobs=-1, verbose=1):\n",
    "    \"\"\"\n",
    "    Train an XGBoost model using TF-IDF features with hyperparameter tuning.\n",
    "    \"\"\"\n",
    "    clean_tf = FunctionTransformer(\n",
    "        func=lambda X: [clean_text(doc) for doc in X],\n",
    "        validate=False\n",
    "    )\n",
    "\n",
    "    pipe = Pipeline([\n",
    "        ('clean', clean_tf),\n",
    "        ('vect',  TfidfVectorizer()),\n",
    "        ('clf',   XGBClassifier(\n",
    "                      eval_metric='logloss',\n",
    "                      random_state=42\n",
    "                  ))\n",
    "    ])\n",
    "    param_grid = {\n",
    "    'clf__n_estimators':  [100, 200, 300, 400],\n",
    "    'clf__max_depth':     [3, 6, 9],\n",
    "    'clf__learning_rate': [0.01, 0.05],\n",
    "    'clf__subsample':     [0.8, 1.0]}\n",
    "    \n",
    "    scorer = make_scorer(f1_score, average='macro')\n",
    "    \n",
    "    grid = GridSearchCV(\n",
    "        estimator    = pipe,\n",
    "        param_grid   = param_grid,\n",
    "        scoring      = scorer,\n",
    "        cv           = cv,\n",
    "        n_jobs       = n_jobs,\n",
    "        verbose      = verbose\n",
    "    )\n",
    "    grid.fit(X_train, y_train)\n",
    "    \n",
    "    return grid.best_params_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac24174",
   "metadata": {},
   "source": [
    "### Auto tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ff0a47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_xgb_bow_autotoken(X_train, y_train, \n",
    "                            pretrained_model='bert-base-uncased',\n",
    "                            cv=3, n_jobs=-1, verbose=1):\n",
    "    \"\"\"\n",
    "    Train an XGBoost model using Bag-of-Words counts\n",
    "    from a HuggingFace AutoTokenizer, with hyperparameter tuning.\n",
    "    \"\"\"\n",
    "    # 1) Load tokenizer\n",
    "    tok = AutoTokenizer.from_pretrained(pretrained_model, use_fast=True)\n",
    "\n",
    "    # 2) Vectorizer that uses the tokenizer to produce tokens\n",
    "    vect = CountVectorizer(\n",
    "        tokenizer     = tok.tokenize,\n",
    "        preprocessor  = lambda x: x,   # no additional cleaning\n",
    "        token_pattern = None,          # disable the default regex\n",
    "        lowercase     = False          # tokenizer handles casing\n",
    "    )\n",
    "\n",
    "    pipe = Pipeline([\n",
    "        ('vect', vect),\n",
    "        ('clf',  XGBClassifier(eval_metric='logloss', random_state=42))\n",
    "    ])\n",
    "\n",
    "    param_grid = {\n",
    "    'clf__n_estimators':  [100, 200, 300, 400],\n",
    "    'clf__max_depth':     [3, 6, 9],\n",
    "    'clf__learning_rate': [0.01, 0.05],\n",
    "    'clf__subsample':     [0.8, 1.0]}\n",
    "\n",
    "    grid = GridSearchCV(\n",
    "        estimator  = pipe,\n",
    "        param_grid = param_grid,\n",
    "        scoring    = make_scorer(f1_score, average='macro'),\n",
    "        cv         = cv,\n",
    "        n_jobs     = n_jobs,\n",
    "        verbose    = verbose\n",
    "    )\n",
    "    grid.fit(X_train, y_train)\n",
    "    return grid.best_params_\n",
    "\n",
    "\n",
    "def train_xgb_tfidf_autotoken(X_train, y_train, \n",
    "                              pretrained_model='bert-base-uncased',\n",
    "                              cv=3, n_jobs=-1, verbose=1):\n",
    "    \"\"\"\n",
    "    Train an XGBoost model using TF-IDF features\n",
    "    from a HuggingFace AutoTokenizer, with hyperparameter tuning.\n",
    "    \"\"\"\n",
    "    tok = AutoTokenizer.from_pretrained(pretrained_model, use_fast=True)\n",
    "\n",
    "    vect = TfidfVectorizer(\n",
    "        tokenizer     = tok.tokenize,\n",
    "        preprocessor  = lambda x: x,\n",
    "        token_pattern = None,\n",
    "        lowercase     = False\n",
    "    )\n",
    "    pipe = Pipeline([\n",
    "        ('vect', vect),\n",
    "        ('clf',  XGBClassifier(eval_metric='logloss', random_state=42))\n",
    "    ])\n",
    "    param_grid = {\n",
    "    'clf__n_estimators':  [100, 200, 300, 400],\n",
    "    'clf__max_depth':     [3, 6, 9],\n",
    "    'clf__learning_rate': [0.01, 0.05],\n",
    "    'clf__subsample':     [0.8, 1.0]}\n",
    "    \n",
    "    grid = GridSearchCV(\n",
    "        estimator  = pipe,\n",
    "        param_grid = param_grid,\n",
    "        scoring    = make_scorer(f1_score, average='macro'),\n",
    "        cv         = cv,\n",
    "        n_jobs     = n_jobs,\n",
    "        verbose    = verbose\n",
    "    )\n",
    "    grid.fit(X_train, y_train)\n",
    "    return grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20aaf2c5",
   "metadata": {},
   "source": [
    "### Auto tokenizer Roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ad1c49bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_xgb_bow_roberta(\n",
    "    X_train, y_train,\n",
    "    pretrained_model: str = \"cardiffnlp/twitter-roberta-base-sentiment-latest\",\n",
    "    cv: int = 3,\n",
    "    n_jobs: int = -1,\n",
    "    verbose: int = 1\n",
    "):\n",
    "    \"\"\"\n",
    "    Train an XGBoost model using Bag-of-Words counts\n",
    "    from the CardiffNLP Twitter RoBERTa tokenizer, with hyperparameter tuning.\n",
    "    \"\"\"\n",
    "    tok = AutoTokenizer.from_pretrained(pretrained_model, use_fast=True)\n",
    "    vect = CountVectorizer(\n",
    "        tokenizer     = tok.tokenize,\n",
    "        preprocessor  = lambda x: x,\n",
    "        token_pattern = None,\n",
    "        lowercase     = False\n",
    "    )\n",
    "    pipe = Pipeline([\n",
    "        ('vect', vect),\n",
    "        ('clf',  XGBClassifier(eval_metric='logloss', random_state=42))\n",
    "    ])\n",
    "    param_grid = {\n",
    "        'clf__n_estimators':  [100, 200, 300, 400],\n",
    "        'clf__max_depth':     [3, 6, 9],\n",
    "        'clf__learning_rate': [0.01, 0.05],\n",
    "        'clf__subsample':     [0.8, 1.0]\n",
    "    }\n",
    "    grid = GridSearchCV(\n",
    "        estimator  = pipe,\n",
    "        param_grid = param_grid,\n",
    "        scoring    = make_scorer(f1_score, average='macro'),\n",
    "        cv         = cv,\n",
    "        n_jobs     = n_jobs,\n",
    "        verbose    = verbose\n",
    "    )\n",
    "    grid.fit(X_train, y_train)\n",
    "    return grid.best_params_\n",
    "\n",
    "\n",
    "def train_xgb_tfidf_roberta(\n",
    "    X_train, y_train,\n",
    "    pretrained_model: str = \"cardiffnlp/twitter-roberta-base-sentiment-latest\",\n",
    "    cv: int = 3,\n",
    "    n_jobs: int = -1,\n",
    "    verbose: int = 1\n",
    "):\n",
    "    \"\"\"\n",
    "    Train an XGBoost model using TF-IDF features\n",
    "    from the CardiffNLP Twitter RoBERTa tokenizer, with hyperparameter tuning.\n",
    "    \"\"\"\n",
    "    tok = AutoTokenizer.from_pretrained(pretrained_model, use_fast=True)\n",
    "    vect = TfidfVectorizer(\n",
    "        tokenizer     = tok.tokenize,\n",
    "        preprocessor  = lambda x: x,\n",
    "        token_pattern = None,\n",
    "        lowercase     = False\n",
    "    )\n",
    "    pipe = Pipeline([\n",
    "        ('vect', vect),\n",
    "        ('clf',  XGBClassifier(eval_metric='logloss', random_state=42))\n",
    "    ])\n",
    "    param_grid = {\n",
    "        'clf__n_estimators':  [100, 200, 300, 400],\n",
    "        'clf__max_depth':     [3, 6, 9],\n",
    "        'clf__learning_rate': [0.01, 0.05],\n",
    "        'clf__subsample':     [0.8, 1.0]\n",
    "    }\n",
    "    grid = GridSearchCV(\n",
    "        estimator  = pipe,\n",
    "        param_grid = param_grid,\n",
    "        scoring    = make_scorer(f1_score, average='macro'),\n",
    "        cv         = cv,\n",
    "        n_jobs     = n_jobs,\n",
    "        verbose    = verbose\n",
    "    )\n",
    "    grid.fit(X_train, y_train)\n",
    "    return grid.best_params_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f641f6db",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "873ac988",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_knn_bow_grid(X_train, y_train, cv=3, n_jobs=-1, verbose=1):\n",
    "    \"\"\"\n",
    "    Train a K-Nearest Neighbors model using Bag-of-Words features with hyperparameter tuning.\n",
    "    \"\"\"\n",
    "    clean_tf = FunctionTransformer(\n",
    "        func=lambda X: [clean_text(doc) for doc in X],\n",
    "        validate=False\n",
    "    )\n",
    "\n",
    "    pipe = Pipeline([\n",
    "        ('clean', clean_tf),\n",
    "        ('vect', CountVectorizer()),\n",
    "        ('clf', KNeighborsClassifier())\n",
    "    ])\n",
    "    \n",
    "    param_grid = {\n",
    "    'clf__n_neighbors': [5, 9, 15],\n",
    "    'clf__weights':    ['uniform', 'distance'],\n",
    "    'clf__metric':     ['euclidean', 'manhattan'],\n",
    "    'clf__leaf_size':  [20, 40],\n",
    "    'clf__p':          [1, 2] \n",
    "    }\n",
    "    \n",
    "    scorer = make_scorer(f1_score, average='macro')\n",
    "    \n",
    "    grid = GridSearchCV(\n",
    "        estimator=pipe,\n",
    "        param_grid=param_grid,\n",
    "        scoring=scorer,\n",
    "        cv=cv,\n",
    "        n_jobs=n_jobs,\n",
    "        verbose=verbose\n",
    "    )\n",
    "    grid.fit(X_train, y_train)\n",
    "    \n",
    "    return grid.best_params_\n",
    "\n",
    "def train_knn_tfidf_grid(X_train, y_train, cv=3, n_jobs=-1, verbose=1):\n",
    "    \"\"\"\n",
    "    Train a K-Nearest Neighbors model using TF-IDF features with hyperparameter tuning.\n",
    "    \"\"\"\n",
    "    clean_tf = FunctionTransformer(\n",
    "        func=lambda X: [clean_text(doc) for doc in X],\n",
    "        validate=False\n",
    "    )\n",
    "    pipe = Pipeline([\n",
    "        ('clean', clean_tf),\n",
    "        ('vect', TfidfVectorizer()),\n",
    "        ('clf', KNeighborsClassifier())\n",
    "    ])\n",
    "    \n",
    "    param_grid = {\n",
    "    'clf__n_neighbors': [5, 9, 15],\n",
    "    'clf__weights':    ['uniform', 'distance'],\n",
    "    'clf__metric':     ['euclidean', 'manhattan'],\n",
    "    'clf__leaf_size':  [20, 40],\n",
    "    'clf__p':          [1, 2] \n",
    "    }\n",
    "    \n",
    "    scorer = make_scorer(f1_score, average='macro')\n",
    "    \n",
    "    grid = GridSearchCV(\n",
    "        estimator=pipe,\n",
    "        param_grid=param_grid,\n",
    "        scoring=scorer,\n",
    "        cv=cv,\n",
    "        n_jobs=n_jobs,\n",
    "        verbose=verbose\n",
    "    )\n",
    "    grid.fit(X_train, y_train)\n",
    "    \n",
    "    return grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf8c70e",
   "metadata": {},
   "source": [
    "### Auto tokenizer\n",
    "(bert-base-uncased)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fccc30d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_knn_bow_autotoken(\n",
    "    X_train, y_train,\n",
    "    pretrained_model: str = \"bert-base-uncased\",\n",
    "    cv: int = 3,\n",
    "    n_jobs: int = -1,\n",
    "    verbose: int = 1\n",
    "):\n",
    "    \"\"\"\n",
    "    Train a KNN model using Bag-of-Words counts from a HuggingFace AutoTokenizer,\n",
    "    with hyperparameter tuning on macro-F1.\n",
    "    \"\"\"\n",
    "    tok = AutoTokenizer.from_pretrained(pretrained_model, use_fast=True)\n",
    "    vect = CountVectorizer(\n",
    "        tokenizer     = tok.tokenize,\n",
    "        preprocessor  = lambda x: x,   # skip extra cleaning\n",
    "        token_pattern = None,          # disable default\n",
    "        lowercase     = False          # tokenizer already lowercases\n",
    "    )\n",
    "    \n",
    "    pipe = Pipeline([\n",
    "        ('vect', vect),\n",
    "        ('clf',  KNeighborsClassifier())\n",
    "    ])\n",
    "    \n",
    "    param_grid = {\n",
    "    'clf__n_neighbors': [5, 9, 15],\n",
    "    'clf__weights':    ['uniform', 'distance'],\n",
    "    'clf__metric':     ['euclidean', 'manhattan'],\n",
    "    'clf__leaf_size':  [20, 40],\n",
    "    'clf__p':          [1, 2] \n",
    "    }\n",
    "    \n",
    "    grid = GridSearchCV(\n",
    "        estimator  = pipe,\n",
    "        param_grid = param_grid,\n",
    "        scoring    = make_scorer(f1_score, average='macro'),\n",
    "        cv         = cv,\n",
    "        n_jobs     = n_jobs,\n",
    "        verbose    = verbose\n",
    "    )\n",
    "    grid.fit(X_train, y_train)\n",
    "    return grid.best_params_\n",
    "\n",
    "def train_knn_tfidf_autotoken(\n",
    "    X_train, y_train,\n",
    "    pretrained_model: str = \"bert-base-uncased\",\n",
    "    cv: int = 3,\n",
    "    n_jobs: int = -1,\n",
    "    verbose: int = 1\n",
    "):\n",
    "    \"\"\"\n",
    "    Train a KNN model using TF-IDF features from a HuggingFace AutoTokenizer,\n",
    "    with hyperparameter tuning on macro-F1.\n",
    "    \"\"\"\n",
    "    tok = AutoTokenizer.from_pretrained(pretrained_model, use_fast=True)\n",
    "    \n",
    "    vect = TfidfVectorizer(\n",
    "        tokenizer     = tok.tokenize,\n",
    "        preprocessor  = lambda x: x,\n",
    "        token_pattern = None,\n",
    "        lowercase     = False\n",
    "    )\n",
    "    \n",
    "    pipe = Pipeline([\n",
    "        ('vect', vect),\n",
    "        ('clf',  KNeighborsClassifier())\n",
    "    ])\n",
    "    \n",
    "    param_grid = {\n",
    "    'clf__n_neighbors': [5, 9, 15],\n",
    "    'clf__weights':    ['uniform', 'distance'],\n",
    "    'clf__metric':     ['euclidean', 'manhattan'],\n",
    "    'clf__leaf_size':  [20, 40],\n",
    "    'clf__p':          [1, 2] \n",
    "    }\n",
    "    \n",
    "    grid = GridSearchCV(\n",
    "        estimator  = pipe,\n",
    "        param_grid = param_grid,\n",
    "        scoring    = make_scorer(f1_score, average='macro'),\n",
    "        cv         = cv,\n",
    "        n_jobs     = n_jobs,\n",
    "        verbose    = verbose\n",
    "    )\n",
    "    grid.fit(X_train, y_train)\n",
    "    return grid.best_params_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1552fa",
   "metadata": {},
   "source": [
    "### Auto tokenizer Roberta\n",
    "(cardiffnlp/twitter-roberta-base-sentiment-latest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d3927084",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_knn_bow_roberta(\n",
    "    X_train, y_train,\n",
    "    pretrained_model: str = \"cardiffnlp/twitter-roberta-base-sentiment-latest\",\n",
    "    cv: int = 3,\n",
    "    n_jobs: int = -1,\n",
    "    verbose: int = 1\n",
    "):\n",
    "    \"\"\"\n",
    "    Train a KNN model using Bag-of-Words counts from the CardiffNLP RoBERTa tokenizer,\n",
    "    with hyperparameter tuning on macro-F1.\n",
    "    \"\"\"\n",
    "\n",
    "    tok = AutoTokenizer.from_pretrained(pretrained_model, use_fast=True)\n",
    "\n",
    "    vect = CountVectorizer(\n",
    "        tokenizer     = tok.tokenize,\n",
    "        preprocessor  = lambda x: x,\n",
    "        token_pattern = None,\n",
    "        lowercase     = False\n",
    "    )\n",
    "\n",
    "    pipe = Pipeline([\n",
    "        ('vect', vect),\n",
    "        ('clf',  KNeighborsClassifier())\n",
    "    ])\n",
    "    param_grid = {\n",
    "        'clf__n_neighbors': [5, 9, 15],\n",
    "        'clf__weights':     ['uniform', 'distance'],\n",
    "        'clf__metric':      ['euclidean', 'manhattan'],\n",
    "        'clf__leaf_size':   [20, 40],\n",
    "        'clf__p':           [1, 2]\n",
    "    }\n",
    "    grid = GridSearchCV(\n",
    "        estimator  = pipe,\n",
    "        param_grid = param_grid,\n",
    "        scoring    = make_scorer(f1_score, average='macro'),\n",
    "        cv         = cv,\n",
    "        n_jobs     = n_jobs,\n",
    "        verbose    = verbose\n",
    "    )\n",
    "    grid.fit(X_train, y_train)\n",
    "    return grid.best_params_\n",
    "\n",
    "\n",
    "def train_knn_tfidf_roberta(\n",
    "    X_train, y_train,\n",
    "    pretrained_model: str = \"cardiffnlp/twitter-roberta-base-sentiment-latest\",\n",
    "    cv: int = 3,\n",
    "    n_jobs: int = -1,\n",
    "    verbose: int = 1\n",
    "):\n",
    "    \"\"\"\n",
    "    Train a KNN model using TF-IDF features from the CardiffNLP RoBERTa tokenizer,\n",
    "    with hyperparameter tuning on macro-F1.\n",
    "    \"\"\"\n",
    "    tok = AutoTokenizer.from_pretrained(pretrained_model, use_fast=True)\n",
    "    vect = TfidfVectorizer(\n",
    "        tokenizer     = tok.tokenize,\n",
    "        preprocessor  = lambda x: x,\n",
    "        token_pattern = None,\n",
    "        lowercase     = False\n",
    "    )\n",
    "    pipe = Pipeline([\n",
    "        ('vect', vect),\n",
    "        ('clf',  KNeighborsClassifier())\n",
    "    ])\n",
    "    param_grid = {\n",
    "        'clf__n_neighbors': [5, 9, 15],\n",
    "        'clf__weights':     ['uniform', 'distance'],\n",
    "        'clf__metric':      ['euclidean', 'manhattan'],\n",
    "        'clf__leaf_size':   [20, 40],\n",
    "        'clf__p':           [1, 2]\n",
    "    }\n",
    "    grid = GridSearchCV(\n",
    "        estimator  = pipe,\n",
    "        param_grid = param_grid,\n",
    "        scoring    = make_scorer(f1_score, average='macro'),\n",
    "        cv         = cv,\n",
    "        n_jobs     = n_jobs,\n",
    "        verbose    = verbose\n",
    "    )\n",
    "    grid.fit(X_train, y_train)\n",
    "    return grid.best_params_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9d8c7a",
   "metadata": {},
   "source": [
    "## Best parameter Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ba86b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters KNN BOW : {'clf__leaf_size': 20, 'clf__metric': 'manhattan', 'clf__n_neighbors': 5, 'clf__p': 1, 'clf__weights': 'distance'}\n",
      "--------------------\n",
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n",
      "Best hyperparameters KNN TF-IDF : {'clf__leaf_size': 20, 'clf__metric': 'euclidean', 'clf__n_neighbors': 15, 'clf__p': 1, 'clf__weights': 'uniform'}\n"
     ]
    }
   ],
   "source": [
    "print(\"MANUAL TOKENIZATION\")\n",
    "print(\"------------------------------------------------------------\")\n",
    "best_params_BOW = train_xgb_bow_grid(X_train, y_train)\n",
    "print(\"Best hyperparameters BOW :\", best_params_BOW)\n",
    "print(\"--------------------\")\n",
    "best_params_TFIDF = train_xgb_tfidf_grid(X_train, y_train)\n",
    "print(\"Best hyperparameters TF-IDF :\", best_params_TFIDF)\n",
    "print(\"--------------------\")\n",
    "best_params_knn_BOW = train_knn_bow_grid(X_train, y_train)\n",
    "print(\"Best hyperparameters KNN BOW :\", best_params_knn_BOW)\n",
    "print(\"--------------------\")\n",
    "best_params_knn_TFIDF = train_knn_tfidf_grid(X_train, y_train)\n",
    "print(\"Best hyperparameters KNN TF-IDF :\", best_params_knn_TFIDF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e70f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"AUTO TOKENIZATION\")\n",
    "print(\"------------------------------------------------------------\")\n",
    "best_params_BOW_autotoken = train_xgb_bow_autotoken(X_train, y_train)\n",
    "print(\"Best hyperparameters BOW with AutoTokenizer:\", best_params_BOW_autotoken)\n",
    "print(\"--------------------\")\n",
    "best_params_TFIDF_autotoken = train_xgb_tfidf_autotoken(X_train, y_train)\n",
    "print(\"Best hyperparameters TF-IDF with AutoTokenizer:\", best_params_TFIDF_autotoken)\n",
    "print(\"--------------------\")\n",
    "best_params_knn_BOW_autotoken = train_knn_bow_autotoken(X_train, y_train)\n",
    "print(\"Best hyperparameters KNN BOW with AutoTokenizer:\", best_params_knn_BOW_autotoken)\n",
    "print(\"--------------------\")\n",
    "best_params_knn_TFIDF_autotoken = train_knn_tfidf_autotoken(X_train, y_train)\n",
    "print(\"Best hyperparameters KNN TF-IDF with AutoTokenizer:\", best_params_knn_TFIDF_autotoken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4c48c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n",
      "Best hyperparameters KNN BOW with RoBERTa tokenizer: {'clf__leaf_size': 20, 'clf__metric': 'euclidean', 'clf__n_neighbors': 5, 'clf__p': 1, 'clf__weights': 'uniform'}\n",
      "--------------------\n",
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n",
      "Best hyperparameters KNN TF-IDF with RoBERTa tokenizer: {'clf__leaf_size': 20, 'clf__metric': 'euclidean', 'clf__n_neighbors': 9, 'clf__p': 1, 'clf__weights': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "print(\"ROBERTA TOKENIZATION\")\n",
    "print(\"------------------------------------------------------------\")\n",
    "best_params_BOW_roberta = train_xgb_bow_roberta(X_train, y_train)\n",
    "print(\"Best hyperparameters BOW with RoBERTa tokenizer:\", best_params_BOW_roberta)\n",
    "print(\"--------------------\")\n",
    "best_params_TFIDF_roberta = train_xgb_tfidf_roberta(X_train, y_train)\n",
    "print(\"Best hyperparameters TF-IDF with RoBERTa tokenizer:\", best_params_TFIDF_roberta)\n",
    "print(\"--------------------\")\n",
    "best_params_knn_BOW_roberta = train_knn_bow_roberta(X_train, y_train)\n",
    "print(\"Best hyperparameters KNN BOW with RoBERTa tokenizer:\", best_params_knn_BOW_roberta)\n",
    "print(\"--------------------\")\n",
    "best_params_knn_TFIDF_roberta = train_knn_tfidf_roberta(X_train, y_train)\n",
    "print(\"Best hyperparameters KNN TF-IDF with RoBERTa tokenizer:\", best_params_knn_TFIDF_roberta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c51fc5",
   "metadata": {},
   "source": [
    "## Preparing Final run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4e76ae",
   "metadata": {},
   "source": [
    "### With manual Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "752572c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Final_run_xgb_bow(X_train, y_train, X_val, y_val, best_params):\n",
    "    X_tr = [clean_text(t) for t in X_train]\n",
    "    X_vl = [clean_text(t) for t in X_val]\n",
    "\n",
    "    vect = CountVectorizer()\n",
    "    X_tr_vec = vect.fit_transform(X_tr)\n",
    "    X_vl_vec = vect.transform(X_vl)\n",
    "\n",
    "    params = {k.split(\"__\",1)[1]: v for k,v in best_params.items()}\n",
    "    model = XGBClassifier(**params, eval_metric=\"logloss\", random_state=42)\n",
    "    \n",
    "    model.fit(X_tr_vec, y_train)\n",
    "\n",
    "    preds_tr = model.predict(X_tr_vec)\n",
    "    preds_vl = model.predict(X_vl_vec)\n",
    "\n",
    "    train_acc = accuracy_score(y_train, preds_tr)\n",
    "    train_f1  = f1_score(y_train, preds_tr, average=\"macro\")\n",
    "    val_acc   = accuracy_score(y_val,   preds_vl)\n",
    "    val_f1    = f1_score(y_val,   preds_vl, average=\"macro\")\n",
    "\n",
    "    print(\"xgb_bow\")\n",
    "    print(\"--------------------\")\n",
    "    print(f\"Train accuracy:  {train_acc:.4f}\")\n",
    "    print(f\"Val   accuracy:  {val_acc:.4f}\")\n",
    "    print(f\"Train f1_macro:  {train_f1:.4f}\")\n",
    "    print(f\"Val   f1_macro:  {val_f1:.4f}\")\n",
    "    print(\"--------------------\")\n",
    "\n",
    "    return train_acc, train_f1, val_acc, val_f1\n",
    "\n",
    "def Final_run_xgb_tfidf(X_train, y_train, X_val, y_val, best_params):\n",
    "    X_tr = [clean_text(t) for t in X_train]\n",
    "    X_vl = [clean_text(t) for t in X_val]\n",
    "\n",
    "    vect = TfidfVectorizer()\n",
    "\n",
    "    X_tr_vec = vect.fit_transform(X_tr)\n",
    "    X_vl_vec = vect.transform(X_vl)\n",
    "\n",
    "    params = {k.split(\"__\",1)[1]: v for k,v in best_params.items()}\n",
    "    model = XGBClassifier(**params, eval_metric=\"logloss\", random_state=42)\n",
    "\n",
    "    model.fit(X_tr_vec, y_train)\n",
    "\n",
    "    preds_tr = model.predict(X_tr_vec)\n",
    "    preds_vl = model.predict(X_vl_vec)\n",
    "\n",
    "    train_acc = accuracy_score(y_train, preds_tr)\n",
    "    train_f1  = f1_score(y_train, preds_tr, average=\"macro\")\n",
    "    val_acc   = accuracy_score(y_val,   preds_vl)\n",
    "    val_f1    = f1_score(y_val,   preds_vl, average=\"macro\")\n",
    "\n",
    "    print(\"xgb_tfidf\")\n",
    "    print(\"--------------------\")\n",
    "    print(f\"Train accuracy:  {train_acc:.4f}\")\n",
    "    print(f\"Val   accuracy:  {val_acc:.4f}\")\n",
    "    print(f\"Train f1_macro:  {train_f1:.4f}\")\n",
    "    print(f\"Val   f1_macro:  {val_f1:.4f}\")\n",
    "    print(\"--------------------\")\n",
    "\n",
    "    return train_acc, train_f1, val_acc, val_f1\n",
    "\n",
    "def Final_run_knn_bow(X_train, y_train, X_val, y_val, best_params):\n",
    "    X_tr = [clean_text(t) for t in X_train]\n",
    "    X_vl = [clean_text(t) for t in X_val]\n",
    "\n",
    "    vect = CountVectorizer()\n",
    "    X_tr_vec = vect.fit_transform(X_tr)\n",
    "    X_vl_vec = vect.transform(X_vl)\n",
    "\n",
    "    params = {k.split(\"__\",1)[1]: v for k,v in best_params.items()}\n",
    "    model = KNeighborsClassifier(**params)\n",
    "\n",
    "    model.fit(X_tr_vec, y_train)\n",
    "\n",
    "    preds_tr = model.predict(X_tr_vec)\n",
    "    preds_vl = model.predict(X_vl_vec)\n",
    "\n",
    "    train_acc = accuracy_score(y_train, preds_tr)\n",
    "    train_f1  = f1_score(y_train, preds_tr, average=\"macro\")\n",
    "    val_acc   = accuracy_score(y_val,   preds_vl)\n",
    "    val_f1    = f1_score(y_val,   preds_vl, average=\"macro\")\n",
    "\n",
    "    print(\"knn_bow\")\n",
    "    print(\"--------------------\")\n",
    "    print(f\"Train accuracy:  {train_acc:.4f}\")\n",
    "    print(f\"Val   accuracy:  {val_acc:.4f}\")\n",
    "    print(f\"Train f1_macro:  {train_f1:.4f}\")\n",
    "    print(f\"Val   f1_macro:  {val_f1:.4f}\")\n",
    "    print(\"--------------------\")\n",
    "\n",
    "    return train_acc, train_f1, val_acc, val_f1\n",
    "\n",
    "def Final_run_knn_tfidf(X_train, y_train, X_val, y_val, best_params):\n",
    "    X_tr = [clean_text(t) for t in X_train]\n",
    "    X_vl = [clean_text(t) for t in X_val]\n",
    "\n",
    "    vect = TfidfVectorizer()\n",
    "    X_tr_vec = vect.fit_transform(X_tr)\n",
    "    X_vl_vec = vect.transform(X_vl)\n",
    "\n",
    "    params = {k.split(\"__\",1)[1]: v for k,v in best_params.items()}\n",
    "    model = KNeighborsClassifier(**params)\n",
    "\n",
    "    model.fit(X_tr_vec, y_train)\n",
    "\n",
    "    preds_tr = model.predict(X_tr_vec)\n",
    "    preds_vl = model.predict(X_vl_vec)\n",
    "\n",
    "    train_acc = accuracy_score(y_train, preds_tr)\n",
    "    train_f1  = f1_score(y_train, preds_tr, average=\"macro\")\n",
    "    val_acc   = accuracy_score(y_val,   preds_vl)\n",
    "    val_f1    = f1_score(y_val,   preds_vl, average=\"macro\")\n",
    "\n",
    "    print(\"knn_tfidf\")\n",
    "    print(\"--------------------\")\n",
    "    print(f\"Train accuracy:  {train_acc:.4f}\")\n",
    "    print(f\"Val   accuracy:  {val_acc:.4f}\")\n",
    "    print(f\"Train f1_macro:  {train_f1:.4f}\")\n",
    "    print(f\"Val   f1_macro:  {val_f1:.4f}\")\n",
    "    print(\"--------------------\")\n",
    "\n",
    "    return train_acc, train_f1, val_acc, val_f1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ec9d1a",
   "metadata": {},
   "source": [
    "### With AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a51e8c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Final_run_xgb_bow_autotoken(\n",
    "    X_train, y_train, X_val, y_val, best_params,\n",
    "    pretrained_model: str = \"bert-base-uncased\"\n",
    "):\n",
    "    tok = AutoTokenizer.from_pretrained(pretrained_model, use_fast=True)\n",
    "    vect = CountVectorizer(\n",
    "        tokenizer     = tok.tokenize,\n",
    "        preprocessor  = lambda x: x,\n",
    "        token_pattern = None,\n",
    "        lowercase     = False\n",
    "    )\n",
    "    X_tr_vec = vect.fit_transform(X_train)\n",
    "    X_vl_vec = vect.transform(X_val)\n",
    "\n",
    "    params = {k.split(\"__\",1)[1]: v for k, v in best_params.items()}\n",
    "    model = XGBClassifier(**params, eval_metric=\"logloss\", random_state=42)\n",
    "    model.fit(X_tr_vec, y_train)\n",
    "\n",
    "    preds_tr = model.predict(X_tr_vec)\n",
    "    preds_vl = model.predict(X_vl_vec)\n",
    "\n",
    "    train_acc = accuracy_score(y_train, preds_tr)\n",
    "    train_f1  = f1_score(y_train, preds_tr, average=\"macro\")\n",
    "    val_acc   = accuracy_score(y_val,   preds_vl)\n",
    "    val_f1    = f1_score(y_val,   preds_vl, average=\"macro\")\n",
    "\n",
    "    print(\"XGB Bow (AutoTokenizer)\")\n",
    "    print(\"------------------------\")\n",
    "    print(f\"Train accuracy:  {train_acc:.4f}\")\n",
    "    print(f\"Val   accuracy:  {val_acc:.4f}\")\n",
    "    print(f\"Train f1_macro:  {train_f1:.4f}\")\n",
    "    print(f\"Val   f1_macro:  {val_f1:.4f}\")\n",
    "    print(\"------------------------\")\n",
    "\n",
    "    return train_acc, train_f1, val_acc, val_f1\n",
    "\n",
    "\n",
    "def Final_run_xgb_tfidf_autotoken(\n",
    "    X_train, y_train, X_val, y_val, best_params,\n",
    "    pretrained_model: str = \"bert-base-uncased\"\n",
    "):\n",
    "    tok = AutoTokenizer.from_pretrained(pretrained_model, use_fast=True)\n",
    "    vect = TfidfVectorizer(\n",
    "        tokenizer     = tok.tokenize,\n",
    "        preprocessor  = lambda x: x,\n",
    "        token_pattern = None,\n",
    "        lowercase     = False\n",
    "    )\n",
    "    X_tr_vec = vect.fit_transform(X_train)\n",
    "    X_vl_vec = vect.transform(X_val)\n",
    "\n",
    "    params = {k.split(\"__\",1)[1]: v for k, v in best_params.items()}\n",
    "    model = XGBClassifier(**params, eval_metric=\"logloss\", random_state=42)\n",
    "    model.fit(X_tr_vec, y_train)\n",
    "\n",
    "    preds_tr = model.predict(X_tr_vec)\n",
    "    preds_vl = model.predict(X_vl_vec)\n",
    "\n",
    "    train_acc = accuracy_score(y_train, preds_tr)\n",
    "    train_f1  = f1_score(y_train, preds_tr, average=\"macro\")\n",
    "    val_acc   = accuracy_score(y_val,   preds_vl)\n",
    "    val_f1    = f1_score(y_val,   preds_vl, average=\"macro\")\n",
    "\n",
    "    print(\"XGB TFIDF (AutoTokenizer)\")\n",
    "    print(\"--------------------------\")\n",
    "    print(f\"Train accuracy:  {train_acc:.4f}\")\n",
    "    print(f\"Val   accuracy:  {val_acc:.4f}\")\n",
    "    print(f\"Train f1_macro:  {train_f1:.4f}\")\n",
    "    print(f\"Val   f1_macro:  {val_f1:.4f}\")\n",
    "    print(\"--------------------------\")\n",
    "\n",
    "    return train_acc, train_f1, val_acc, val_f1\n",
    "\n",
    "\n",
    "def Final_run_knn_bow_autotoken(\n",
    "    X_train, y_train, X_val, y_val, best_params,\n",
    "    pretrained_model: str = \"bert-base-uncased\"\n",
    "):\n",
    "    tok = AutoTokenizer.from_pretrained(pretrained_model, use_fast=True)\n",
    "    vect = CountVectorizer(\n",
    "        tokenizer     = tok.tokenize,\n",
    "        preprocessor  = lambda x: x,\n",
    "        token_pattern = None,\n",
    "        lowercase     = False\n",
    "    )\n",
    "    X_tr_vec = vect.fit_transform(X_train)\n",
    "    X_vl_vec = vect.transform(X_val)\n",
    "\n",
    "    params = {k.split(\"__\",1)[1]: v for k, v in best_params.items()}\n",
    "    model = KNeighborsClassifier(**params)\n",
    "    model.fit(X_tr_vec, y_train)\n",
    "\n",
    "    preds_tr = model.predict(X_tr_vec)\n",
    "    preds_vl = model.predict(X_vl_vec)\n",
    "\n",
    "    train_acc = accuracy_score(y_train, preds_tr)\n",
    "    train_f1  = f1_score(y_train, preds_tr, average=\"macro\")\n",
    "    val_acc   = accuracy_score(y_val,   preds_vl)\n",
    "    val_f1    = f1_score(y_val,   preds_vl, average=\"macro\")\n",
    "\n",
    "    print(\"KNN Bow (AutoTokenizer)\")\n",
    "    print(\"------------------------\")\n",
    "    print(f\"Train accuracy:  {train_acc:.4f}\")\n",
    "    print(f\"Val   accuracy:  {val_acc:.4f}\")\n",
    "    print(f\"Train f1_macro:  {train_f1:.4f}\")\n",
    "    print(f\"Val   f1_macro:  {val_f1:.4f}\")\n",
    "    print(\"------------------------\")\n",
    "\n",
    "    return train_acc, train_f1, val_acc, val_f1\n",
    "\n",
    "\n",
    "def Final_run_knn_tfidf_autotoken(\n",
    "    X_train, y_train, X_val, y_val, best_params,\n",
    "    pretrained_model: str = \"bert-base-uncased\"\n",
    "):\n",
    "    tok = AutoTokenizer.from_pretrained(pretrained_model, use_fast=True)\n",
    "    vect = TfidfVectorizer(\n",
    "        tokenizer     = tok.tokenize,\n",
    "        preprocessor  = lambda x: x,\n",
    "        token_pattern = None,\n",
    "        lowercase     = False\n",
    "    )\n",
    "    X_tr_vec = vect.fit_transform(X_train)\n",
    "    X_vl_vec = vect.transform(X_val)\n",
    "\n",
    "    params = {k.split(\"__\",1)[1]: v for k, v in best_params.items()}\n",
    "    model = KNeighborsClassifier(**params)\n",
    "    model.fit(X_tr_vec, y_train)\n",
    "\n",
    "    preds_tr = model.predict(X_tr_vec)\n",
    "    preds_vl = model.predict(X_vl_vec)\n",
    "\n",
    "    train_acc = accuracy_score(y_train, preds_tr)\n",
    "    train_f1  = f1_score(y_train, preds_tr, average=\"macro\")\n",
    "    val_acc   = accuracy_score(y_val,   preds_vl)\n",
    "    val_f1    = f1_score(y_val,   preds_vl, average=\"macro\")\n",
    "\n",
    "    print(\"KNN TFIDF (AutoTokenizer)\")\n",
    "    print(\"--------------------------\")\n",
    "    print(f\"Train accuracy:  {train_acc:.4f}\")\n",
    "    print(f\"Val   accuracy:  {val_acc:.4f}\")\n",
    "    print(f\"Train f1_macro:  {train_f1:.4f}\")\n",
    "    print(f\"Val   f1_macro:  {val_f1:.4f}\")\n",
    "    print(\"--------------------------\")\n",
    "\n",
    "    return train_acc, train_f1, val_acc, val_f1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeee937b",
   "metadata": {},
   "source": [
    "### With Autotokenizer Roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "907c34eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROBERTA_MODEL = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "\n",
    "def Final_run_xgb_bow_roberta(\n",
    "    X_train, y_train, X_val, y_val, best_params,\n",
    "    pretrained_model: str = ROBERTA_MODEL\n",
    "):\n",
    "    tok = AutoTokenizer.from_pretrained(pretrained_model, use_fast=True)\n",
    "    vect = CountVectorizer(\n",
    "        tokenizer     = tok.tokenize,\n",
    "        preprocessor  = lambda x: x,\n",
    "        token_pattern = None,\n",
    "        lowercase     = False\n",
    "    )\n",
    "    X_tr_vec = vect.fit_transform(X_train)\n",
    "    X_vl_vec = vect.transform(X_val)\n",
    "\n",
    "    params = {k.split(\"__\",1)[1]: v for k, v in best_params.items()}\n",
    "    model = XGBClassifier(**params, eval_metric=\"logloss\", random_state=42)\n",
    "    model.fit(X_tr_vec, y_train)\n",
    "\n",
    "    preds_tr = model.predict(X_tr_vec)\n",
    "    preds_vl = model.predict(X_vl_vec)\n",
    "\n",
    "    train_acc = accuracy_score(y_train, preds_tr)\n",
    "    train_f1  = f1_score(y_train, preds_tr, average=\"macro\")\n",
    "    val_acc   = accuracy_score(y_val,   preds_vl)\n",
    "    val_f1    = f1_score(y_val,   preds_vl, average=\"macro\")\n",
    "\n",
    "    print(\"XGB BOW (RoBERTa Tokenizer)\")\n",
    "    print(\"----------------------------\")\n",
    "    print(f\"Train accuracy:  {train_acc:.4f}\")\n",
    "    print(f\"Val   accuracy:  {val_acc:.4f}\")\n",
    "    print(f\"Train f1_macro:  {train_f1:.4f}\")\n",
    "    print(f\"Val   f1_macro:  {val_f1:.4f}\")\n",
    "    print(\"----------------------------\")\n",
    "\n",
    "    return train_acc, train_f1, val_acc, val_f1\n",
    "\n",
    "def Final_run_xgb_tfidf_roberta(\n",
    "    X_train, y_train, X_val, y_val, best_params,\n",
    "    pretrained_model: str = ROBERTA_MODEL\n",
    "):\n",
    "    tok = AutoTokenizer.from_pretrained(pretrained_model, use_fast=True)\n",
    "    vect = TfidfVectorizer(\n",
    "        tokenizer     = tok.tokenize,\n",
    "        preprocessor  = lambda x: x,\n",
    "        token_pattern = None,\n",
    "        lowercase     = False\n",
    "    )\n",
    "    X_tr_vec = vect.fit_transform(X_train)\n",
    "    X_vl_vec = vect.transform(X_val)\n",
    "\n",
    "    params = {k.split(\"__\",1)[1]: v for k, v in best_params.items()}\n",
    "    model = XGBClassifier(**params, eval_metric=\"logloss\", random_state=42)\n",
    "    model.fit(X_tr_vec, y_train)\n",
    "\n",
    "    preds_tr = model.predict(X_tr_vec)\n",
    "    preds_vl = model.predict(X_vl_vec)\n",
    "\n",
    "    train_acc = accuracy_score(y_train, preds_tr)\n",
    "    train_f1  = f1_score(y_train, preds_tr, average=\"macro\")\n",
    "    val_acc   = accuracy_score(y_val,   preds_vl)\n",
    "    val_f1    = f1_score(y_val,   preds_vl, average=\"macro\")\n",
    "\n",
    "    print(\"XGB TFIDF (RoBERTa Tokenizer)\")\n",
    "    print(\"------------------------------\")\n",
    "    print(f\"Train accuracy:  {train_acc:.4f}\")\n",
    "    print(f\"Val   accuracy:  {val_acc:.4f}\")\n",
    "    print(f\"Train f1_macro:  {train_f1:.4f}\")\n",
    "    print(f\"Val   f1_macro:  {val_f1:.4f}\")\n",
    "    print(\"------------------------------\")\n",
    "\n",
    "    return train_acc, train_f1, val_acc, val_f1\n",
    "\n",
    "def Final_run_knn_bow_roberta(\n",
    "    X_train, y_train, X_val, y_val, best_params,\n",
    "    pretrained_model: str = ROBERTA_MODEL\n",
    "):\n",
    "    tok = AutoTokenizer.from_pretrained(pretrained_model, use_fast=True)\n",
    "    vect = CountVectorizer(\n",
    "        tokenizer     = tok.tokenize,\n",
    "        preprocessor  = lambda x: x,\n",
    "        token_pattern = None,\n",
    "        lowercase     = False\n",
    "    )\n",
    "    X_tr_vec = vect.fit_transform(X_train)\n",
    "    X_vl_vec = vect.transform(X_val)\n",
    "\n",
    "    params = {k.split(\"__\",1)[1]: v for k, v in best_params.items()}\n",
    "    model = KNeighborsClassifier(**params)\n",
    "    model.fit(X_tr_vec, y_train)\n",
    "\n",
    "    preds_tr = model.predict(X_tr_vec)\n",
    "    preds_vl = model.predict(X_vl_vec)\n",
    "\n",
    "    train_acc = accuracy_score(y_train, preds_tr)\n",
    "    train_f1  = f1_score(y_train, preds_tr, average=\"macro\")\n",
    "    val_acc   = accuracy_score(y_val,   preds_vl)\n",
    "    val_f1    = f1_score(y_val,   preds_vl, average=\"macro\")\n",
    "\n",
    "    print(\"KNN BOW (RoBERTa Tokenizer)\")\n",
    "    print(\"----------------------------\")\n",
    "    print(f\"Train accuracy:  {train_acc:.4f}\")\n",
    "    print(f\"Val   accuracy:  {val_acc:.4f}\")\n",
    "    print(f\"Train f1_macro:  {train_f1:.4f}\")\n",
    "    print(f\"Val   f1_macro:  {val_f1:.4f}\")\n",
    "    print(\"----------------------------\")\n",
    "\n",
    "    return train_acc, train_f1, val_acc, val_f1\n",
    "\n",
    "def Final_run_knn_tfidf_roberta(\n",
    "    X_train, y_train, X_val, y_val, best_params,\n",
    "    pretrained_model: str = ROBERTA_MODEL\n",
    "):\n",
    "    tok = AutoTokenizer.from_pretrained(pretrained_model, use_fast=True)\n",
    "    vect = TfidfVectorizer(\n",
    "        tokenizer     = tok.tokenize,\n",
    "        preprocessor  = lambda x: x,\n",
    "        token_pattern = None,\n",
    "        lowercase     = False\n",
    "    )\n",
    "    X_tr_vec = vect.fit_transform(X_train)\n",
    "    X_vl_vec = vect.transform(X_val)\n",
    "\n",
    "    params = {k.split(\"__\",1)[1]: v for k, v in best_params.items()}\n",
    "    model = KNeighborsClassifier(**params)\n",
    "    model.fit(X_tr_vec, y_train)\n",
    "\n",
    "    preds_tr = model.predict(X_tr_vec)\n",
    "    preds_vl = model.predict(X_vl_vec)\n",
    "\n",
    "    train_acc = accuracy_score(y_train, preds_tr)\n",
    "    train_f1  = f1_score(y_train, preds_tr, average=\"macro\")\n",
    "    val_acc   = accuracy_score(y_val,   preds_vl)\n",
    "    val_f1    = f1_score(y_val,   preds_vl, average=\"macro\")\n",
    "\n",
    "    print(\"KNN TFIDF (RoBERTa Tokenizer)\")\n",
    "    print(\"------------------------------\")\n",
    "    print(f\"Train accuracy:  {train_acc:.4f}\")\n",
    "    print(f\"Val   accuracy:  {val_acc:.4f}\")\n",
    "    print(f\"Train f1_macro:  {train_f1:.4f}\")\n",
    "    print(f\"Val   f1_macro:  {val_f1:.4f}\")\n",
    "    print(\"------------------------------\")\n",
    "\n",
    "    return train_acc, train_f1, val_acc, val_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3fc796d",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91069901",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy_xboost_bow, train_f1_xboost_bow, val_accuracy_xboost_bow, val_f1_xboost_bow = Final_run_xgb_bow(X_train, y_train, X_val, y_val, best_params_BOW)\n",
    "train_accuracy_xboost_tfidf, train_f1_xboost_tfidf, val_accuracy_xboost_tfidf, val_f1_xboost_tfidf = Final_run_xgb_tfidf(X_train, y_train, X_val, y_val, best_params_TFIDF)\n",
    "\n",
    "train_accuracy_knn_bow, train_f1_knn_bow, val_accuracy_knn_bow, val_f1_knn_bow = Final_run_knn_bow(X_train, y_train, X_val, y_val, best_params_knn_BOW)\n",
    "train_accuracy_knn_tfidf, train_f1_knn_tfidf, val_accuracy_knn_tfidf, val_f1_knn_tfidf = Final_run_knn_tfidf(X_train, y_train, X_val, y_val, best_params_knn_TFIDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc1fc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy_xboost_bow_autotoken, train_f1_xboost_bow_autotoken, val_accuracy_xboost_bow_autotoken, val_f1_xboost_bow_autotoken = Final_run_xgb_bow_autotoken(X_train, y_train, X_val, y_val, best_params_BOW_autotoken)\n",
    "train_accuracy_xboost_tfidf_autotoken, train_f1_xboost_tfidf_autotoken, val_accuracy_xboost_tfidf_autotoken, val_f1_xboost_tfidf_autotoken = Final_run_xgb_tfidf_autotoken(X_train, y_train, X_val, y_val, best_params_TFIDF_autotoken)\n",
    "\n",
    "train_accuracy_knn_bow_autotoken, train_f1_knn_bow_autotoken, val_accuracy_knn_bow_autotoken, val_f1_knn_bow_autotoken = Final_run_knn_bow_autotoken(X_train, y_train, X_val, y_val, best_params_knn_BOW_autotoken)\n",
    "train_accuracy_knn_tfidf_autotoken, train_f1_knn_tfidf_autotoken, val_accuracy_knn_tfidf_autotoken, val_f1_knn_tfidf_autotoken = Final_run_knn_tfidf_autotoken(X_train, y_train, X_val, y_val, best_params_knn_TFIDF_autotoken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab5e333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN BOW (RoBERTa Tokenizer)\n",
      "----------------------------\n",
      "Train accuracy:  0.7545\n",
      "Val   accuracy:  0.7014\n",
      "Train f1_macro:  0.5936\n",
      "Val   f1_macro:  0.4697\n",
      "----------------------------\n",
      "KNN TFIDF (RoBERTa Tokenizer)\n",
      "------------------------------\n",
      "Train accuracy:  1.0000\n",
      "Val   accuracy:  0.7700\n",
      "Train f1_macro:  1.0000\n",
      "Val   f1_macro:  0.6472\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "train_accuracy_xboost_bow_roberta, train_f1_xboost_bow_roberta, val_accuracy_xboost_bow_roberta, val_f1_xboost_bow_roberta = Final_run_xgb_bow_roberta(X_train, y_train, X_val, y_val, best_params_BOW_roberta)\n",
    "train_accuracy_xboost_tfidf_roberta, train_f1_xboost_tfidf_roberta, val_accuracy_xboost_tfidf_roberta, val_f1_xboost_tfidf_roberta = Final_run_xgb_tfidf_roberta(X_train, y_train, X_val, y_val, best_params_TFIDF_roberta)\n",
    "\n",
    "train_accuracy_knn_bow_roberta, train_f1_knn_bow_roberta, val_accuracy_knn_bow_roberta, val_f1_knn_bow_roberta = Final_run_knn_bow_roberta(X_train, y_train, X_val, y_val, best_params_knn_BOW_roberta)\n",
    "train_accuracy_knn_tfidf_roberta, train_f1_knn_tfidf_roberta, val_accuracy_knn_tfidf_roberta, val_f1_knn_tfidf_roberta = Final_run_knn_tfidf_roberta(X_train, y_train, X_val, y_val, best_params_knn_TFIDF_roberta)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06bf5c7",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679d0e16",
   "metadata": {},
   "source": [
    "In this section we evaluate the different models previously build and how the different methods used can impact accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51533823",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    'XGB BOW', 'XGB TFIDF', 'KNN BOW', 'KNN TFIDF',\n",
    "    'XGB BOW (Auto)', 'XGB TFIDF (Auto)', 'KNN BOW (Auto)', 'KNN TFIDF (Auto)',\n",
    "    'XGB BOW (RoBERTa)', 'XGB TFIDF (RoBERTa)', 'KNN BOW (RoBERTa)', 'KNN TFIDF (RoBERTa)'\n",
    "]\n",
    "\n",
    "train_acc = np.array([\n",
    "    train_accuracy_xboost_bow,\n",
    "    train_accuracy_xboost_tfidf,\n",
    "    train_accuracy_knn_bow,\n",
    "    train_accuracy_knn_tfidf,\n",
    "    train_accuracy_xboost_bow_autotoken,\n",
    "    train_accuracy_xboost_tfidf_autotoken,\n",
    "    train_accuracy_knn_bow_autotoken,\n",
    "    train_accuracy_knn_tfidf_autotoken,\n",
    "    train_accuracy_xboost_bow_roberta,\n",
    "    train_accuracy_xboost_tfidf_roberta,\n",
    "    train_accuracy_knn_bow_roberta,\n",
    "    train_accuracy_knn_tfidf_roberta\n",
    "])\n",
    "\n",
    "val_acc = np.array([\n",
    "    val_accuracy_xboost_bow,\n",
    "    val_accuracy_xboost_tfidf,\n",
    "    val_accuracy_knn_bow,\n",
    "    val_accuracy_knn_tfidf,\n",
    "    val_accuracy_xboost_bow_autotoken,\n",
    "    val_accuracy_xboost_tfidf_autotoken,\n",
    "    val_accuracy_knn_bow_autotoken,\n",
    "    val_accuracy_knn_tfidf_autotoken,\n",
    "    val_accuracy_xboost_bow_roberta,\n",
    "    val_accuracy_xboost_tfidf_roberta,\n",
    "    val_accuracy_knn_bow_roberta,\n",
    "    val_accuracy_knn_tfidf_roberta\n",
    "])\n",
    "\n",
    "train_f1 = np.array([\n",
    "    train_f1_xboost_bow,\n",
    "    train_f1_xboost_tfidf,\n",
    "    train_f1_knn_bow,\n",
    "    train_f1_knn_tfidf,\n",
    "    train_f1_xboost_bow_autotoken,\n",
    "    train_f1_xboost_tfidf_autotoken,\n",
    "    train_f1_knn_bow_autotoken,\n",
    "    train_f1_knn_tfidf_autotoken,\n",
    "    train_f1_xboost_bow_roberta,\n",
    "    train_f1_xboost_tfidf_roberta,\n",
    "    train_f1_knn_bow_roberta,\n",
    "    train_f1_knn_tfidf_roberta\n",
    "])\n",
    "\n",
    "val_f1 = np.array([\n",
    "    val_f1_xboost_bow,\n",
    "    val_f1_xboost_tfidf,\n",
    "    val_f1_knn_bow,\n",
    "    val_f1_knn_tfidf,\n",
    "    val_f1_xboost_bow_autotoken,\n",
    "    val_f1_xboost_tfidf_autotoken,\n",
    "    val_f1_knn_bow_autotoken,\n",
    "    val_f1_knn_tfidf_autotoken,\n",
    "    val_f1_xboost_bow_roberta,\n",
    "    val_f1_xboost_tfidf_roberta,\n",
    "    val_f1_knn_bow_roberta,\n",
    "    val_f1_knn_tfidf_roberta\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aed3ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x = np.arange(len(models))\n",
    "width = 0.35\n",
    "\n",
    "# Accuracy plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(x - width/2, train_acc, width, label='Train')\n",
    "plt.bar(x + width/2, val_acc,   width, label='Validation')\n",
    "plt.xticks(x, models, rotation=45, ha='right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Train vs Validation Accuracy for All Models')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# F1-macro plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(x - width/2, train_f1, width, label='Train')\n",
    "plt.bar(x + width/2, val_f1,   width, label='Validation')\n",
    "plt.xticks(x, models, rotation=45, ha='right')\n",
    "plt.ylabel('F1 Macro Score')\n",
    "plt.title('Train vs Validation F1 Macro for All Models')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873c027b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "diff_acc = train_acc - val_acc\n",
    "diff_f1  = train_f1  - val_f1\n",
    "\n",
    "order_acc = np.argsort(-diff_acc)\n",
    "order_f1  = np.argsort(-diff_f1)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6), sharey=False)\n",
    "\n",
    "# 1) Accuracy difference\n",
    "axes[0].barh(\n",
    "    np.array(models)[order_acc],\n",
    "    diff_acc[order_acc]\n",
    ")\n",
    "axes[0].set_title('Train ‚Äì Validation Accuracy Difference')\n",
    "axes[0].set_xlabel('Accuracy Difference')\n",
    "axes[0].invert_yaxis()  # largest difference at top\n",
    "\n",
    "# 2) F1‚Äêmacro difference\n",
    "axes[1].barh(\n",
    "    np.array(models)[order_f1],\n",
    "    diff_f1[order_f1]\n",
    ")\n",
    "axes[1].set_title('Train ‚Äì Validation F1-Macro Difference')\n",
    "axes[1].set_xlabel('F1-Macro Difference')\n",
    "axes[1].invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DM2425",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
